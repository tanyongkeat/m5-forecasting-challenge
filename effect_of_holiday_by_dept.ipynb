{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import datetime\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# import pmdarima\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from fbprophet import Prophet\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataframe outputed from data_munging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pickle.load(open('full_df', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I load the calendar.csv and downcast the fields to save RAM usage. Dummy fields are created by combining the presence of events from $event\\_name\\_1$ and $event\\_name\\_2$ fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv(f'calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downcast_dict = {'wm_yr_wk': np.int16,\n",
    "                'weekday': 'category',\n",
    "                'wday': np.int16,\n",
    "                'month': np.int16,\n",
    "                'year': np.int16,\n",
    "                'd': 'category',\n",
    "                'snap_CA': np.uint8,\n",
    "                'snap_TX': np.uint8,\n",
    "                'snap_WI': np.uint8,\n",
    "                'event_name_1': 'category',\n",
    "                'event_type_1': 'category',\n",
    "                'event_name_2': 'category',\n",
    "                'event_type_2': 'category',\n",
    "                'event': np.uint8}\n",
    "\n",
    "event_types = calendar.event_type_1.unique()[1:] # remove null\n",
    "for event_type in event_types:\n",
    "    calendar['event_' + event_type.lower()] = ((calendar.event_type_1 == event_type) | (calendar.event_type_2 == event_type)).map({True: 1, False: 0})\n",
    "    downcast_dict['event_' + event_type.lower()] = np.uint8\n",
    "event_names = calendar.event_name_1.unique()[1:]\n",
    "for event_name in event_names:\n",
    "    calendar['event_' + event_name.lower()] = ((calendar.event_name_1 == event_name) | (calendar.event_name_2 == event_name)).map({True: 1, False: 0})\n",
    "    downcast_dict['event_' + event_name.lower()] = np.uint8\n",
    "calendar['event'] = (~calendar.event_name_1.isnull()).map({True: 1, False: 0})\n",
    "\n",
    "calendar = calendar.astype(downcast_dict)\n",
    "\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "\n",
    "calendar.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then collect the dates for each holidays and store them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = calendar[~calendar.event_name_1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_and_date = dict()\n",
    "for event in holidays.event_name_1.unique():\n",
    "    holidays_and_date[event.lower()] = holidays[(holidays.event_name_1 == event)\n",
    "                                                | (holidays.event_name_2 == event)].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the department id from the $id$ field using regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['dept_id'] = full_df['id'].str.extract('([A-Z]+_\\d+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a dataframe, by, is created by grouping the full_df according to $dept\\_id$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by = full_df.groupby(['dept_id']).resample('d').mean()\n",
    "by = by.reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $demand$ of each department is plotted for the whole period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dept_id in by.dept_id.unique():\n",
    "    by[by.dept_id == dept_id].demand.plot(label=dept_id)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two are functions used to plot effects of holidays by department. The output will be demonstrated below for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(dt): #get the dates 14 days before and after the target date\n",
    "    return pd.to_datetime(dt-np.timedelta64(14, 'D')), pd.to_datetime(dt+np.timedelta64(14, 'D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = holidays.event_name_1.unique()\n",
    "def holidays_effect_on(dept_id):\n",
    "    # the maximum number of years is 6 years for holidays\n",
    "    fig, ax = plt.subplots(nrows=len(events)*2, ncols=3, figsize=(20,180)) # split the holidays into 2 by 3\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for i in range(len(events)):\n",
    "        event = events[i].lower()\n",
    "        color = 'red' if i%2 else 'blue' # change the color for interleaving holidays to show each holiday clearly\n",
    "        i *= 2\n",
    "        dates = pd.to_datetime(holidays_and_date[event])\n",
    "        for j in range(len(dates)):\n",
    "            date = dates[j]\n",
    "            lower_window, upper_window = get_window(date)\n",
    "            window_df = by.query(f'dept_id == \"{dept_id}\"')[lower_window:upper_window]\n",
    "            current_ax = ax[i+j//3][j%3]\n",
    "            if len(window_df) < 23:\n",
    "                current_ax.axes.xaxis.set_ticklabels([])\n",
    "                current_ax.axes.yaxis.set_ticklabels([])\n",
    "                continue\n",
    "            window_df.demand.plot(ax=current_ax, color=color)\n",
    "            title = event + ' ' + date.strftime('%Y-%m-%d') + ' wday ' + str(window_df.iloc[0].wday)\n",
    "            current_ax.set_title(title)\n",
    "            current_ax.axvline(x=date) # ouput a vertical line to clearly indicate which day the holiday occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See and list how many different deparments there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.dept_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the weekly $demand$ for the targetted department to compare how the holidays actually affect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_id = \"FOODS_1\"\n",
    "by.query(f'dept_id == {dept_id}').groupby('wday')['demand'].mean().plot()\n",
    "plt.title(dept_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Why *weekly* demand is plotted but not monthly or yearly?__ Because there is strong weekly seasonality, as shown in the acf_plot below (the notebook is run on kaggle because my local machine is not good enough to handle this large dataset, so there will not be ouput shown here, instead I will use some figure to demonstrate where clarification is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(by.query(f'dept_id == {dept_id}').demand.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![acf plot showing strong weekly seasonality](figures/acf_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the method written above, part of the output is demonstrated as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_effect_on(dept_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![demonstration](figures/effect-of-holiday-by-department.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e.g. We can see that there is a surge of demand every year before the easter day, while martinlutherkingday doesn't have much impact on the seasonality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
